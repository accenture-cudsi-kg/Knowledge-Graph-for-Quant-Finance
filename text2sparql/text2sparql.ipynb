{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUEWgs9VtyKS",
        "outputId": "c9c542f5-7c78-495c-d68a-f7b573ab4b6c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/gdrive/MyDrive/Capstone/t2s/\n",
        "from utilites import *\n",
        "!pip install deeppavlov\n",
        "!pip install transformers\n",
        "from deeppavlov import build_model\n",
        "template_matching_model = build_model('query_pr', download=True)\n",
        "\n",
        "!pip install finbert-embedding\n",
        "from finbert_embedding.embedding import FinbertEmbedding\n",
        "finbert = FinbertEmbedding()\n",
        "\n",
        "!pip install spacy\n",
        "!pip install xgboost\n",
        "!pip install sister\n",
        "!pip install fuzzywuzzy\n",
        "!pip install spacy[transformers]\n",
        "!python -m spacy download en_core_web_trf\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "import re\n",
        "import csv\n",
        "import pandas as pd\n",
        "import bs4\n",
        "import requests\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import string\n",
        "import re\n",
        "import sister\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from scipy.spatial.distance import cosine\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "\n",
        "file_name = \"/content/gdrive/MyDrive/Capstone/t2s/XGB_template_classifier.pkl\"\n",
        "\n",
        "# load\n",
        "XGB_template_classifier = pickle.load(open(file_name, \"rb\"))\n",
        "\n",
        "\n",
        "\n",
        "with open(\"/content/gdrive/MyDrive/Capstone/t2s/relations_embeddings.pkl\", \"rb\") as f: # \"rb\" because we want to read in binary mode\n",
        "    relation_embeddings = pickle.load(f)\n",
        "\n",
        "with open(\"/content/gdrive/MyDrive/Capstone/t2s/entities_embeddings.pkl\", \"rb\") as f: # \"rb\" because we want to read in binary mode\n",
        "    entity_embeddings = pickle.load(f)\n",
        "\n",
        "import json\n",
        "\n",
        "# loading ontologies\n",
        "with open(\"/content/gdrive/MyDrive/Capstone/t2s/allennlp_ontology.json\", 'r') as f:\n",
        "  ontology = json.load(f)\n",
        "relations=list(ontology[\"relation\"].keys())\n",
        "\n",
        "entities_ontology=list(ontology[\"entities\"].keys())\n",
        "\n",
        "bert_template={4:[\"SELECT (count(*) as? count) WHERE {<http://crypto.org/ENTITY_CLASS/ENTITY><http://crypto.org/RELATION_CLASS/RELATION> ?o.}\",\n",
        "                  \"SELECT (count(*) as? count) WHERE {?s <http://crypto.org/RELATION_CLASS/RELATION> <http://crypto.org/ENTITY_CLASS/ENTITY>.}\"]\n",
        "            ,5:\"\"}\n",
        "XGB_template={2:[1,\"SELECT DISTINCT ?o WHERE { <http://crypto.org/ENTITY_CLASS/ENTITY> <http://crypto.org/RELATION_CLASS/RELATION> ?o.}\",\n",
        "                 \"SELECT DISTINCT ?s WHERE { ?s <http://crypto.org/RELATION_CLASS/RELATION> <http://crypto.org/ENTITY_CLASS/ENTITY>.}\"],\n",
        "           16:[2,\"SELECT DISTINCT ?o WHERE { <http://crypto.org/SUBJECT1_CLASS/SUBJECT1><http://crypto.org/RELATION1_CLASS/RELATION1> ?o. <http://crypto.org/SUBJECT2_CLASS/SUBJECT2><http://crypto.org/RELATION2_CLASS/RELATION2> ?o. }\"],\n",
        "           305:[2,\"\"]}\n",
        "ner = spacy.load('en_core_web_trf')\n"
      ],
      "metadata": {
        "id": "gD3iSEJlu4vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text2sparql(query):\n",
        "  sparql_query_list=[]\n",
        "\n",
        "  template_id,n_entities, query_templates=template_classification(query)\n",
        "  \n",
        "  if template_id==1:\n",
        "    relation=get_single_relation(query)\n",
        "    \n",
        "    if relation==\"Not found\":\n",
        "      relation_class=\"Not found\"\n",
        "    else:\n",
        "      relation_class=ontology[\"relation\"][relation]\n",
        "    entity=get_single_entity(query)\n",
        "    if entity == \"Not found\":\n",
        "      entity_class==\"Not found\"\n",
        "    else:\n",
        "      entity_class=ontology[\"entities\"][entity]\n",
        "    \n",
        "    if (entity!=\"Not found\" and relation!=\"Not found\" ):\n",
        "      for query_template in query_templates:\n",
        "        sparql_query_list.append(query_template.replace(\"ENTITY_CLASS\",entity_class.replace(\" \",\"_\")).replace(\"ENTITY\",entity.replace(\" \",\"_\")).replace(\"RELATION_CLASS\",relation_class.replace(\" \",\"_\")).replace(\"RELATION\",relation.replace(\" \",\"_\")))\n",
        "    else:\n",
        "      sparql_query_list.append(\"Not found\")\n",
        "\n",
        "  if n_entities==100:\n",
        "    entities=get_entities(query)\n",
        "    if len(entities)!=0:\n",
        "      for entity in entities:\n",
        "        entity_class=ontology[\"entities\"][entity]\n",
        "        sparql_query_list.append(query_template.replace(\"ENTITY_CLASS\",entity_class.replace(\" \",\"_\")).replace(\"ENTITY\",entity.replace(\" \",\"_\")))\n",
        "    else:\n",
        "      sparql_query_list.append(\"Not found\")\n",
        "\n",
        "  \n",
        "  return sparql_query_list\n",
        "\n",
        "\n",
        "query1=\"What are the papers that Ramit Sawhney authored?\"\n",
        "query2=\"How many papers has Ramit Sawhney authored?\"\n",
        "\n",
        "text2sparql(query1)"
      ],
      "metadata": {
        "id": "71KG2C44wLfO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}