# -*- coding: utf-8 -*-
"""preprocessing_pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HUANEyS9pIuFTHMezsxBrb_3onNbwnHz
"""

class clean_text(sentence):
  """
  Takes in raw sentence, process it via the following four steps:
  (i) rm_garbage_tokens: removes whitespaces, newlines, tabs
  (ii) lemmatize: returns lemmatized sentences
  (iii) generic_sentences_removal: deletes sentences which don't have any named entities
  (iv) coreference resolution: TBD, borrow from Elin/Ridwan
  (v) replace generic phrases: TBD, handwritten rules to replace certain common phrases like "this work" etc with a more 
  context appropriate phrase
  
  """

  def get_doc(self,sentence):
    """
    Parse sentence the spacy way
    """
    return (nlp(sentence))

  def rm_garbage_tokens(self,doc):
    """ 
    This function will remove extra whitespaces, newlines, and tabs from text
    input_text: "text" of type "String". 
    return value: "text" after extra whitespaces removed .

    Example:
    Input : How   are\\   you\n   doing   ?
    Output : How are you doing ?         
    """
    text = text.replace('\\n', ' ').replace('\n', ' ').replace('\t',' ').replace('\\', ' ').replace('. com', '.com')
    pattern = re.compile(r'\s+') 
    Without_whitespace = re.sub(pattern, ' ', text)
    # There are some instances where there is no space after '?' & ')', 
    # So I am replacing these with one space so that It will not consider two words as one token.
    text = Without_whitespace.replace('?', ' ? ').replace(')', ') ')
    
    return text

  def lemmatized(doc):
    """
    To deal with duplicate relations like analyze, analyzed
    """  
    
    lemmatized_sentence=""
    for token in doc:
      lemmatized_sentence=lemmatized_sentence+token.lemma_+" "
    
    return(lemmatized_sentence[:-1])
  

  def generic_sentences_removal(doc):
    if doc.ents:
      for ent in doc.ents:
          return(ent.text+' - ' +str(ent.start_char) +' - '+ str(ent.end_char) +' - '+ent.label_+ ' - '+str(spacy.explain(ent.label_)))
    else:
        return('No named entities found.')


  def replace_generic_phrases():
    """
    For eg. replace "this work" with the name of the paper

    """
    pass