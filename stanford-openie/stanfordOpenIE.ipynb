{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ngvljtCyfZnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71134e19-87a5-42b3-d699-c9d54c91775b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp==2.1.0\n",
            "  Downloading allennlp-2.1.0-py3-none-any.whl (585 kB)\n",
            "\u001b[K     |████████████████████████████████| 585 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting allennlp-models==2.1.0\n",
            "  Downloading allennlp_models-2.1.0-py3-none-any.whl (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.1.0)\n",
            "Collecting boto3<2.0,>=1.14\n",
            "  Downloading boto3-1.26.7-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 74.9 MB/s \n",
            "\u001b[?25hCollecting filelock<3.1,>=3.0\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.2.5)\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (8.12.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (3.6.4)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 56.8 MB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 69.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (2.2.4)\n",
            "Collecting torchvision<0.9.0,>=0.8.1\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 64.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.0.2)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 63.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (4.62.3)\n",
            "Collecting torch<1.8.0,>=1.6.0\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (1.4.1)\n",
            "Collecting transformers<4.4,>=4.1\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp==2.1.0) (0.99)\n",
            "Collecting py-rouge==1.1\n",
            "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting conllu==4.4\n",
            "  Downloading conllu-4.4-py2.py3-none-any.whl (15 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.7\n",
            "  Downloading botocore-1.29.7-py3-none-any.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 44.6 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 77.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.7->boto3<2.0,>=1.14->allennlp==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.7->boto3<2.0,>=1.14->allennlp==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==2.1.0) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==2.1.0) (2021.10.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1,>=2.1.0->allennlp==2.1.0) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.1,>=2.1.0->allennlp==2.1.0) (4.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.1,>=2.1.0->allennlp==2.1.0) (3.7.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp==2.1.0) (3.17.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.9.0,>=0.8.1->allennlp==2.1.0) (7.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.4,>=4.1->allennlp==2.1.0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<4.4,>=4.1->allennlp==2.1.0) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp-models==2.1.0) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==2.1.0) (1.5.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<4.4,>=4.1->allennlp==2.1.0) (3.0.7)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==2.1.0) (21.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.4,>=4.1->allennlp==2.1.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.4,>=4.1->allennlp==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp==2.1.0) (3.1.0)\n",
            "Building wheels for collected packages: overrides, jsonnet, word2number, sacremoses\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=f648133c411cc151eb5d95df2bc7e6a8b6b0e8c11214b7f0bebcbcea5c7cbc89\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp37-cp37m-linux_x86_64.whl size=3997181 sha256=3ae900b0102b6c7bb9065296006f8685a41f71245b852461f85dae093f72ca94\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/6b/48/a168ed5f8d01c50268605eff341c29126286763607bf707e3b\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=da11be76c538b92c173ed3296d6bddbdb488f7b1e994dc0ea6a7d3cac2db7fc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=b2ebfc8a543eead0345ed9c868c1b33f4e7b600c3c396b6c16a03f5016472d80\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built overrides jsonnet word2number sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, torch, tokenizers, sacremoses, s3transfer, filelock, transformers, torchvision, tensorboardX, sentencepiece, overrides, jsonpickle, jsonnet, boto3, word2number, py-rouge, ftfy, conllu, allennlp, allennlp-models\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.6.0\n",
            "    Uninstalling filelock-3.6.0:\n",
            "      Successfully uninstalled filelock-3.6.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed allennlp-2.1.0 allennlp-models-2.1.0 boto3-1.26.7 botocore-1.29.7 conllu-4.4 filelock-3.0.12 ftfy-6.1.1 jmespath-1.0.1 jsonnet-0.19.1 jsonpickle-2.2.0 overrides-3.1.0 py-rouge-1.1 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 tensorboardX-2.5.1 tokenizers-0.10.3 torch-1.7.1 torchvision-0.8.2 transformers-4.3.3 urllib3-1.25.11 word2number-1.1\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
            "\u001b[K     |████████████████████████████████| 691 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.25.11)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234927 sha256=f943be660ccb7140d6b8a0807796fe2552f108be986f531795e0cb79beccc747\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/e3/f2/1de1c2e3ed742e1df73e0f15d58864e50c7e64f607b548d6cf\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-2.2.0 stanza-1.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lcG-mDCzw9um",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "f673e06532ef4ea6a048d928130c2571",
            "be06c3de2e9a400984291e42c7f3fa5e",
            "70f3eb7850b54ec895c4ef9127cea5b1",
            "95150d9cbb464e84a79fe9ad49d3729a",
            "4fb33aa5803c4068ac32534dc1735c80",
            "a52495fcff8145b199504e78e6e20a69",
            "630305e60aae4f919deeecbf6970f71a",
            "56488c9aa9df43e095e49cbc22affc5b",
            "be46836dea894eefa5ce6b6557191642",
            "6a6abeea72104f15ab1dea5ec64f5cc3",
            "0ac0b9ab794a415a92a092083dec6700"
          ]
        },
        "outputId": "1c45c8a6-1370-44db-da5a-c7f7669bebea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-11 02:54:05 INFO: Installing CoreNLP package into /root/stanza_corenlp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f673e06532ef4ea6a048d928130c2571",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip:   0%|        …"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from allennlp.predictors.predictor import Predictor\n",
        "import allennlp_models.tagging\n",
        "import stanza\n",
        "stanza.install_corenlp()\n",
        "from stanza.server import CoreNLPClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FhWXy-QYLi0i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "bacf141c77924929bab65e7318721226",
            "cfe1cd69e6934b2394e87c049bfeafa9",
            "f34734035ff7474da955db56d62ec081",
            "a3ce6a5651a149848207482404f4ada1",
            "9665dcafe47a4ac0bd8799f1583c61e9",
            "8a21a48a3deb49a3beb144943cf048f7",
            "a4cd8a7bcd4649729aa0df972c08ef28",
            "8ffbb8914adf4bf3b3b96ae46a6b07f5",
            "3add14c6d81b456593e3dd62f2971819",
            "9eb5ece87a7c4430bd6841f02bc2ff44",
            "2027c78052e748758b6aa242f257756e",
            "1a4809dac6cc41a29926ef329a408acf",
            "a21f1a0bd93746d1a34cbca986f21013",
            "879707ddb2e649f586a0fdb38a640a7d",
            "c91a5bfd73584db192b5edf5e017dda0",
            "974dc072b36945f29c51300c2da13f01",
            "be752455baa2482d81b3fed0ac331bed",
            "190e6b0b97c6469eaf40b760223b491a",
            "f5671cdc8ecc40d78d7d6a154f1357a6",
            "d311bf22556c4f7d87d171f15fcb5458",
            "491b4b8abc3b4d21bc3e0ffe8a127f34",
            "5d7b6d9187494bb3af42387cabac692b",
            "8b11ccc534e3453f9630d3f57c820ab9",
            "1340dc8433c041f8bbe5c8825828f1f8",
            "85199b1136574be884cb07b67a178813",
            "0471ce884d784e208c9c213c80adf839",
            "552c7e39b9fd4ca59ada72830b6e2253",
            "5b5232d7961342369376afed5f9e604e",
            "a49dcdb9dfc142cc9f9ff60912b61b01",
            "5f7c8ad196674d00ba7cc64bcd0b2ec2",
            "df4d573758ad4d3e870210dcf4f33352",
            "8799cb11300c4278b7a91ca68ed15326",
            "4a8b5a242486412da048c2414d102bc0"
          ]
        },
        "outputId": "62ae2f51-0c57-4255-bd3f-219c3dcb212d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Plugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "downloading: 100%|##########| 1345986155/1345986155 [00:27<00:00, 48072222.28B/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bacf141c77924929bab65e7318721226",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a4809dac6cc41a29926ef329a408acf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b11ccc534e3453f9630d3f57c820ab9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import re\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import json\n",
        "import os\n",
        "\n",
        "WORD = re.compile(r\"\\w+\")\n",
        "coref = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2021.03.10.tar.gz\")\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/GoogleDrive/')\n",
        "# data_dir = '/content/GoogleDrive/MyDrive/results/meta-transcript-readable-pymupdf.txt'\n",
        "!unzip cleaned_json.zip\n",
        "data_dir = '/content/cleaned_json'"
      ],
      "metadata": {
        "id": "hp6ulGgu1u01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27cc0ab-ae34-4690-c97e-dd4ed9648167"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cleaned_json.zip\n",
            "   creating: cleaned_json/\n",
            "  inflating: cleaned_json/1803.05663.json  \n",
            "  inflating: cleaned_json/2010.12415.json  \n",
            "  inflating: cleaned_json/2204.13102.json  \n",
            "  inflating: cleaned_json/2205.06338.json  \n",
            "  inflating: cleaned_json/2102.07425.json  \n",
            "  inflating: cleaned_json/2010.15403.json  \n",
            "  inflating: cleaned_json/2010.01337.json  \n",
            "  inflating: cleaned_json/2109.12142.json  \n",
            "  inflating: cleaned_json/1912.11166.json  \n",
            "  inflating: cleaned_json/1912.03311.json  \n",
            "  inflating: cleaned_json/2008.09667.json  \n",
            "  inflating: cleaned_json/2109.15052.json  \n",
            "  inflating: cleaned_json/2112.15036.json  \n",
            "  inflating: cleaned_json/2011.02612.json  \n",
            "  inflating: cleaned_json/2201.02729.json  \n",
            "  inflating: cleaned_json/1903.00472.json  \n",
            "  inflating: cleaned_json/2204.12929.json  \n",
            "  inflating: cleaned_json/1908.02591.json  \n",
            "  inflating: cleaned_json/1805.08550.json  \n",
            "  inflating: cleaned_json/2201.12893.json  \n",
            "  inflating: cleaned_json/2201.05906.json  \n",
            "  inflating: cleaned_json/2004.04605.json  \n",
            "  inflating: cleaned_json/2206.03386.json  \n",
            "  inflating: cleaned_json/1910.12281.json  \n",
            "  inflating: cleaned_json/2109.01214.json  \n",
            "  inflating: cleaned_json/1906.03430.json  \n",
            "  inflating: cleaned_json/2105.08133.json  \n",
            "  inflating: cleaned_json/2203.04579.json  \n",
            "  inflating: cleaned_json/2102.08378.json  \n",
            "  inflating: cleaned_json/2101.02778.json  \n",
            "  inflating: cleaned_json/1903.06033.json  \n",
            "  inflating: cleaned_json/2004.06985.json  \n",
            "  inflating: cleaned_json/1902.09253.json  \n",
            "  inflating: cleaned_json/2106.07104.json  \n",
            "  inflating: cleaned_json/2206.06320.json  \n",
            "  inflating: cleaned_json/1811.03146.json  \n",
            "  inflating: cleaned_json/2105.06827.json  \n",
            "  inflating: cleaned_json/2103.00395.json  \n",
            "  inflating: cleaned_json/1804.06261.json  \n",
            "  inflating: cleaned_json/2008.05653.json  \n",
            "  inflating: cleaned_json/2003.13517.json  \n",
            "  inflating: cleaned_json/1708.04532.json  \n",
            "  inflating: cleaned_json/1905.09647.json  \n",
            "  inflating: cleaned_json/2006.14473.json  \n",
            "  inflating: cleaned_json/2206.07831.json  \n",
            "  inflating: cleaned_json/2102.07001.json  \n",
            "  inflating: cleaned_json/1812.09452.json  \n",
            "  inflating: cleaned_json/1907.03577.json  \n",
            "  inflating: cleaned_json/2105.12336.json  \n",
            "  inflating: cleaned_json/1901.04967.json  \n",
            "  inflating: cleaned_json/2205.00335.json  \n",
            "  inflating: cleaned_json/1403.6378.json  \n",
            "  inflating: cleaned_json/2011.01712.json  \n",
            "  inflating: cleaned_json/2105.00707.json  \n",
            "  inflating: cleaned_json/1911.11819.json  \n",
            "  inflating: cleaned_json/1405.4498.json  \n",
            "  inflating: cleaned_json/2208.01445.json  \n",
            "  inflating: cleaned_json/2109.10958.json  \n",
            "  inflating: cleaned_json/2101.06236.json  \n",
            "  inflating: cleaned_json/1904.05315.json  \n",
            "  inflating: cleaned_json/2209.04385.json  \n",
            "  inflating: cleaned_json/1710.10377.json  \n",
            "  inflating: cleaned_json/1712.10287.json  \n",
            "  inflating: cleaned_json/2107.00298.json  \n",
            "  inflating: cleaned_json/2203.10465.json  \n",
            "  inflating: cleaned_json/2005.06610.json  \n",
            "  inflating: cleaned_json/1805.00558.json  \n",
            "  inflating: cleaned_json/2106.02187.json  \n",
            "  inflating: cleaned_json/2109.02776.json  \n",
            "  inflating: cleaned_json/2203.14601.json  \n",
            "  inflating: cleaned_json/1909.01268.json  \n",
            "  inflating: cleaned_json/2005.00114.json  \n",
            "  inflating: cleaned_json/1808.08585.json  \n",
            "  inflating: cleaned_json/1911.08944.json  \n",
            "  inflating: cleaned_json/2112.06552.json  \n",
            "  inflating: cleaned_json/2009.11007.json  \n",
            "  inflating: cleaned_json/2106.12961.json  \n",
            "  inflating: cleaned_json/1909.10679.json  \n",
            "  inflating: cleaned_json/2112.06807.json  \n",
            "  inflating: cleaned_json/2004.05870.json  \n",
            "  inflating: cleaned_json/1809.08403.json  \n",
            "  inflating: cleaned_json/1308.3892.json  \n",
            "  inflating: cleaned_json/2003.00803.json  \n",
            "  inflating: cleaned_json/2207.04004.json  \n",
            "  inflating: cleaned_json/2002.12274.json  \n",
            "  inflating: cleaned_json/1806.11348.json  \n",
            "  inflating: cleaned_json/2206.08401.json  \n",
            "  inflating: cleaned_json/1412.4503.json  \n",
            "  inflating: cleaned_json/2112.07386.json  \n",
            "  inflating: cleaned_json/1707.07977.json  \n",
            "  inflating: cleaned_json/2004.01499.json  \n",
            "  inflating: cleaned_json/1905.03211.json  \n",
            "  inflating: cleaned_json/1406.6496.json  \n",
            "  inflating: cleaned_json/1703.00308.json  \n",
            "  inflating: cleaned_json/1804.05916.json  \n",
            "  inflating: cleaned_json/2203.12606.json  \n",
            "  inflating: cleaned_json/2003.04967.json  \n",
            "  inflating: cleaned_json/2107.12447.json  \n",
            "  inflating: cleaned_json/1803.03088.json  \n",
            "  inflating: cleaned_json/1904.05472.json  \n",
            "  inflating: cleaned_json/2201.09790.json  \n",
            "  inflating: cleaned_json/1709.08090.json  \n",
            "  inflating: cleaned_json/1404.4275.json  \n",
            "  inflating: cleaned_json/1907.00558.json  \n",
            "  inflating: cleaned_json/2202.10918.json  \n",
            "  inflating: cleaned_json/1806.08386.json  \n",
            "  inflating: cleaned_json/2010.08900.json  \n",
            "  inflating: cleaned_json/1904.12346.json  \n",
            "  inflating: cleaned_json/1809.07856.json  \n",
            "  inflating: cleaned_json/1904.05028.json  \n",
            "  inflating: cleaned_json/1805.03143.json  \n",
            "  inflating: cleaned_json/2004.00550.json  \n",
            "  inflating: cleaned_json/1807.05360.json  \n",
            "  inflating: cleaned_json/1706.07216.json  \n",
            "  inflating: cleaned_json/2206.00648.json  \n",
            "  inflating: cleaned_json/2207.07315.json  \n",
            "  inflating: cleaned_json/2009.10030.json  \n",
            "  inflating: cleaned_json/2107.10634.json  \n",
            "  inflating: cleaned_json/2101.03891.json  \n",
            "  inflating: cleaned_json/2010.12736.json  \n",
            "  inflating: cleaned_json/1901.04770.json  \n",
            "  inflating: cleaned_json/1709.08621.json  \n",
            "  inflating: cleaned_json/1909.04903.json  \n",
            "  inflating: cleaned_json/2109.12166.json  \n",
            "  inflating: cleaned_json/2206.05081.json  \n",
            "  inflating: cleaned_json/2210.02633.json  \n",
            "  inflating: cleaned_json/2012.14860.json  \n",
            "  inflating: cleaned_json/1408.1494.json  \n",
            "  inflating: cleaned_json/2003.11352.json  \n",
            "  inflating: cleaned_json/1906.11968.json  \n",
            "  inflating: cleaned_json/1811.05935.json  \n",
            "  inflating: cleaned_json/1912.03556.json  \n",
            "  inflating: cleaned_json/2102.05448.json  \n",
            "  inflating: cleaned_json/2205.04290.json  \n",
            "  inflating: cleaned_json/1902.01941.json  \n",
            "  inflating: cleaned_json/2005.09356.json  \n",
            "  inflating: cleaned_json/1904.09403.json  \n",
            "  inflating: cleaned_json/1803.08405.json  \n",
            "  inflating: cleaned_json/1909.10957.json  \n",
            "  inflating: cleaned_json/1707.07618.json  \n",
            "  inflating: cleaned_json/1905.08444.json  \n",
            "  inflating: cleaned_json/1911.06400.json  \n",
            "  inflating: cleaned_json/2111.09057.json  \n",
            "  inflating: cleaned_json/2208.07254.json  \n",
            "  inflating: cleaned_json/2002.07117.json  \n",
            "  inflating: cleaned_json/2101.01261.json  \n",
            "  inflating: cleaned_json/1707.03746.json  \n",
            "  inflating: cleaned_json/2102.04591.json  \n",
            "  inflating: cleaned_json/1406.0268.json  \n",
            "  inflating: cleaned_json/1702.00215.json  \n",
            "  inflating: cleaned_json/1912.10105.json  \n",
            "  inflating: cleaned_json/2107.13926.json  \n",
            "  inflating: cleaned_json/1503.06704.json  \n",
            "  inflating: cleaned_json/2209.12664.json  \n",
            "  inflating: cleaned_json/1811.10109.json  \n",
            "  inflating: cleaned_json/1805.04460.json  \n",
            "  inflating: cleaned_json/2207.02989.json  \n",
            "  inflating: cleaned_json/1706.01437.json  \n",
            "  inflating: cleaned_json/2102.08187.json  \n",
            "  inflating: cleaned_json/2103.12461.json  \n",
            "  inflating: cleaned_json/1912.03270.json  \n",
            "  inflating: cleaned_json/2103.00173.json  \n",
            "  inflating: cleaned_json/1705.05334.json  \n",
            "  inflating: cleaned_json/2102.02865.json  \n",
            "  inflating: cleaned_json/1805.10128.json  \n",
            "  inflating: cleaned_json/2106.11446.json  \n",
            "  inflating: cleaned_json/2104.01764.json  \n",
            "  inflating: cleaned_json/1506.01513.json  \n",
            "  inflating: cleaned_json/1912.05228.json  \n",
            "  inflating: cleaned_json/1805.04698.json  \n",
            "  inflating: cleaned_json/1906.08933.json  \n",
            "  inflating: cleaned_json/2004.00047.json  \n",
            "  inflating: cleaned_json/2111.02067.json  \n",
            "  inflating: cleaned_json/1809.02769.json  \n",
            "  inflating: cleaned_json/2010.07402.json  \n",
            "  inflating: cleaned_json/2204.05781.json  \n",
            "  inflating: cleaned_json/2001.03099.json  \n",
            "  inflating: cleaned_json/1911.08647.json  \n",
            "  inflating: cleaned_json/1901.04928.json  \n",
            "  inflating: cleaned_json/2202.08967.json  \n",
            "  inflating: cleaned_json/2109.10662.json  \n",
            "  inflating: cleaned_json/2004.08167.json  \n",
            "  inflating: cleaned_json/1911.01330.json  \n",
            "  inflating: cleaned_json/2201.06072.json  \n",
            "  inflating: cleaned_json/1912.01952.json  \n",
            "  inflating: cleaned_json/1902.07855.json  \n",
            "  inflating: cleaned_json/1810.09521.json  \n",
            "  inflating: cleaned_json/1906.01293.json  \n",
            "  inflating: cleaned_json/2109.15051.json  \n",
            "  inflating: cleaned_json/2001.01127.json  \n",
            "  inflating: cleaned_json/2004.09212.json  \n",
            "  inflating: cleaned_json/1704.08175.json  \n",
            "  inflating: cleaned_json/2111.15351.json  \n",
            "  inflating: cleaned_json/2010.01031.json  \n",
            "  inflating: cleaned_json/1906.05740.json  \n",
            "  inflating: cleaned_json/1707.01284.json  \n",
            "  inflating: cleaned_json/2110.14317.json  \n",
            "  inflating: cleaned_json/1807.08644.json  \n",
            "  inflating: cleaned_json/2009.06874.json  \n",
            "  inflating: cleaned_json/1605.01354.json  \n",
            "  inflating: cleaned_json/2111.11315.json  \n",
            "  inflating: cleaned_json/2205.00974.json  \n",
            "  inflating: cleaned_json/1312.2048.json  \n",
            "  inflating: cleaned_json/1804.02350.json  \n",
            "  inflating: cleaned_json/2106.14204.json  \n",
            "  inflating: cleaned_json/1708.04955.json  \n",
            "  inflating: cleaned_json/2209.05559.json  \n",
            "  inflating: cleaned_json/2108.09750.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c_UKdzmZLl_3"
      },
      "outputs": [],
      "source": [
        "# Cosine similarity between two vectors\n",
        "def get_cosine(vec1, vec2):\n",
        "  intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "  numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "  sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
        "  sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
        "  denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "  if not denominator:\n",
        "      return 0.0\n",
        "  else:\n",
        "      return float(numerator) / denominator\n",
        "\n",
        "# Convert string to a vector\n",
        "def text_to_vector(text):\n",
        "    words = WORD.findall(text)\n",
        "    return Counter(words)\n",
        "\n",
        "# check if 2 triples exist with similar subject, object, predicate longer subject is taken\n",
        "def subset_phrase(triples, simScore):\n",
        "  n = len(triples)\n",
        "  new_triple = triples[:]\n",
        "  for i in range(n):\n",
        "    firstTri = triples[i]\n",
        "    for j in range(i + 1, n):\n",
        "      secondTri = triples[j]\n",
        "      text1 = firstTri[0] + \" \" + firstTri[1] + \" \" + firstTri[2] + \" \" + firstTri[3]\n",
        "      text2 = secondTri[0] + \" \" + secondTri[1] + \" \" + secondTri[2] + \" \" + secondTri[3]\n",
        "      vector1 = text_to_vector(text1)\n",
        "      vector2 = text_to_vector(text2)\n",
        "      # Doing the above eliminates worrying about scenarios of exactly the same subject, object or predicate\n",
        "      if get_cosine(vector1, vector2) >= simScore:\n",
        "        # temp = firstTri if len(firstTri[0]) > len(secondTri[0]) else secondTri #can make this based on the subject, not text\n",
        "        temp = firstTri if len(text1) > len(text2) else secondTri\n",
        "        if temp == secondTri:\n",
        "          if firstTri in new_triple:\n",
        "            new_triple.remove(firstTri)\n",
        "        elif secondTri in new_triple:\n",
        "            new_triple.remove(secondTri)\n",
        "  return new_triple\n",
        "\n",
        "# return true or false if triple is a valid triple\n",
        "def filter_triple(triple):\n",
        "  DAY_OF_THE_WEEK = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
        "  subject = triple[0]\n",
        "  predicate = triple[1]\n",
        "  object_ = triple[2]\n",
        "  doc_sub = nlp(subject)\n",
        "  doc_obj = nlp(object_)\n",
        "  doc_pred = nlp(predicate)\n",
        "  subject_pos = [token.pos_ for token in doc_sub] #all parts of speech\n",
        "  object_pos = [token.pos_ for token in doc_obj] #all parts of speech\n",
        "  predicate_pos = [token.pos_ for token in doc_pred] #all parts of speech\n",
        "  all_words_day_week = [True if word.lower() in DAY_OF_THE_WEEK else False for word in subject.split()]\n",
        "  contains_day_of_week = any(all_words_day_week) #performs OR operation of booleans in list\n",
        "  if 'NOUN' not in subject_pos and 'PROPN' not in subject_pos and contains_day_of_week:\n",
        "    return False\n",
        "  elif ('VERB' in subject_pos) or ('VERB' in object_pos):\n",
        "    return False\n",
        "  elif any([\"PRON\" in subject_pos,\"PRON\" in predicate_pos, \"PRON\" in object_pos]):\n",
        "    return False\n",
        "  elif subject == object_:\n",
        "    return False\n",
        "  return True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def addTriple(document, simThresh):\n",
        "  allTriples = []\n",
        "  triples = []\n",
        "  for sentence in document['sentences']:\n",
        "    # Add temporal relation\n",
        "    cursentTemp = \"\"\n",
        "    for ele in sentence['entitymentions']:\n",
        "      if ele['ner'] == \"DATE\":\n",
        "        temp = ele['text'] \n",
        "        cursentTemp = temp if len(temp) > len(cursentTemp) else cursentTemp    \n",
        "    sentTrip = []\n",
        "    for triple in sentence['openie']:\n",
        "      if filter_triple((triple['subject'], triple['relation'], triple['object'])):\n",
        "        sentTrip.append((triple['subject'], triple['relation'], triple['object'], cursentTemp))\n",
        "    valid_triples = subset_phrase(sentTrip, simThresh) #more similarity score increases the number of sentences retrieved since we're making sure sentences are extremely close in order to drop the shorter one. \n",
        "    triples.append(valid_triples)\n",
        "    \n",
        "  triples = [item for sublist in triples for item in sublist]\n",
        "  for ele in triples:\n",
        "    tmp_arg = ele[3]\n",
        "    if len(tmp_arg) > 0:\n",
        "      allTriples.append((ele[2], ele[1], ele[3]))\n",
        "    allTriples.append((ele[0], ele[1], ele[2]))\n",
        "  return allTriples"
      ],
      "metadata": {
        "id": "YpXn-yhy2fQl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPROCESS TEXT\n",
        "def clean_text(sentence):\n",
        "  \"\"\"\n",
        "  Input sentence: Raw sentence\n",
        "  Output sentence: cleaned sentence with - \n",
        "                  (i) no extra whitespaces, no new lines, no tabs\n",
        "                  (ii) lemmatized sentence\n",
        "                  (iii) generic sentences with no NER are returned as empty string\n",
        "\n",
        "  \"\"\"\n",
        "  doc=nlp(sentence)\n",
        "  # lemmatization\n",
        "  lemmatized_sentence=\"\"\n",
        "  for token in doc:\n",
        "    if token.lemma_ !=\"-PRON-\":\n",
        "      lemmatized_sentence=lemmatized_sentence+token.lemma_+\" \"\n",
        "    else:\n",
        "      if token.lemma_ == \" . \":\n",
        "        print(\"MAD OO\")\n",
        "      lemmatized_sentence=lemmatized_sentence+str(token)+\" \"\n",
        "  sentence=lemmatized_sentence[:-1]\n",
        "\n",
        "  # removing whitespace, /n, tabs\n",
        "  sentence = sentence.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ')\n",
        "  pattern = re.compile(r'\\s+') \n",
        "  Without_whitespace = re.sub(pattern, ' ', sentence)\n",
        "  # There are some instances where there is no space after '?' & ')', \n",
        "  # So I am replacing these with one space so that It will not consider two words as one token.\n",
        "  sentence = Without_whitespace.replace('?', ' ? ').replace(')', ') ')\n",
        "  return sentence\n",
        "\n",
        "\n",
        "text = \"Ridwan is not a person. He is nice.\"\n",
        "print(clean_text(text))"
      ],
      "metadata": {
        "id": "to-KKhEwTFKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3a31d3-7616-4305-9075-fd28d728c275"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridwan be not a person . He be nice .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load files from source document\n",
        "allTriples = []\n",
        "files = sorted(os.listdir(data_dir))\n",
        "# allText = \"\"\n",
        "for file in files:\n",
        "  with open(f'{data_dir}/{file}') as f:\n",
        "    d = json.load(f)\n",
        "  text = d['text']\n",
        "  all_authors = \"\"\n",
        "  for ele in d['auhtors']:\n",
        "    all_authors += ele + \", \"\n",
        "  allTriples.append((all_authors[:-2], 'author(s)', d['title']))\n",
        "  if len(text) > 0:\n",
        "    text = clean_text(text)\n",
        "    coref_text = coref.coref_resolved(document=text)\n",
        "    with CoreNLPClient(timeout=150000000, be_quiet=False, annotators=['ner', 'openie'], memory='25G', endpoint='http://localhost:9001') as client:\n",
        "      document = client.annotate(coref_text, output_format='json', properties={\"openie.triple.all_nominals\": True})\n",
        "      allTriples.extend(addTriple(document, 0.5))\n",
        "    # allText += coref_text + \" \""
      ],
      "metadata": {
        "id": "Sa_S7yJrdzNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc0c595f-cf35-4e3c-aed6-3d79065e0aae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-11 02:55:48 INFO: Writing properties to tmp file: corenlp_server-08bd815a86e24245.props\n",
            "2022-11-11 02:55:48 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-08bd815a86e24245.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 02:56:44 INFO: Writing properties to tmp file: corenlp_server-14f8c14dc3e94695.props\n",
            "2022-11-11 02:56:44 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-14f8c14dc3e94695.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 02:57:32 INFO: Writing properties to tmp file: corenlp_server-4abd927eed2d41dd.props\n",
            "2022-11-11 02:57:32 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-4abd927eed2d41dd.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 02:58:11 INFO: Writing properties to tmp file: corenlp_server-6ded38310f8a4e38.props\n",
            "2022-11-11 02:58:11 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-6ded38310f8a4e38.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 02:58:49 INFO: Writing properties to tmp file: corenlp_server-c832343fd6eb41a8.props\n",
            "2022-11-11 02:58:49 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-c832343fd6eb41a8.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 02:59:29 INFO: Writing properties to tmp file: corenlp_server-9631f47d4adc4c0f.props\n",
            "2022-11-11 02:59:29 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-9631f47d4adc4c0f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:00:11 INFO: Writing properties to tmp file: corenlp_server-0665d94d6adf4bf9.props\n",
            "2022-11-11 03:00:11 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-0665d94d6adf4bf9.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:01:04 INFO: Writing properties to tmp file: corenlp_server-e8926457338549f9.props\n",
            "2022-11-11 03:01:04 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-e8926457338549f9.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:02:02 INFO: Writing properties to tmp file: corenlp_server-3bfc84bb6ed8417c.props\n",
            "2022-11-11 03:02:02 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-3bfc84bb6ed8417c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:02:38 INFO: Writing properties to tmp file: corenlp_server-4fb8ea7f1e7e49fa.props\n",
            "2022-11-11 03:02:38 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-4fb8ea7f1e7e49fa.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:03:10 INFO: Writing properties to tmp file: corenlp_server-59903466b3e44140.props\n",
            "2022-11-11 03:03:10 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-59903466b3e44140.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:03:43 INFO: Writing properties to tmp file: corenlp_server-26829c8bf3774839.props\n",
            "2022-11-11 03:03:43 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-26829c8bf3774839.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:04:17 INFO: Writing properties to tmp file: corenlp_server-f3c2c1a61a7e41bd.props\n",
            "2022-11-11 03:04:17 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-f3c2c1a61a7e41bd.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:04:50 INFO: Writing properties to tmp file: corenlp_server-28807ca61c4f47c7.props\n",
            "2022-11-11 03:04:50 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-28807ca61c4f47c7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:05:32 INFO: Writing properties to tmp file: corenlp_server-a61ea096732e4bfc.props\n",
            "2022-11-11 03:05:32 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a61ea096732e4bfc.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:06:09 INFO: Writing properties to tmp file: corenlp_server-b1e7be9401574f2d.props\n",
            "2022-11-11 03:06:09 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b1e7be9401574f2d.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:06:46 INFO: Writing properties to tmp file: corenlp_server-a140c9fafc1042e1.props\n",
            "2022-11-11 03:06:46 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a140c9fafc1042e1.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:07:22 INFO: Writing properties to tmp file: corenlp_server-8ea0472995584f46.props\n",
            "2022-11-11 03:07:22 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-8ea0472995584f46.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:08:09 INFO: Writing properties to tmp file: corenlp_server-9a1f0ec32e8f4d22.props\n",
            "2022-11-11 03:08:09 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-9a1f0ec32e8f4d22.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:08:40 INFO: Writing properties to tmp file: corenlp_server-2484b4e8a975435d.props\n",
            "2022-11-11 03:08:40 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2484b4e8a975435d.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:09:14 INFO: Writing properties to tmp file: corenlp_server-126fe16efc84406e.props\n",
            "2022-11-11 03:09:14 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-126fe16efc84406e.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:09:46 INFO: Writing properties to tmp file: corenlp_server-51ced849b5c6482a.props\n",
            "2022-11-11 03:09:46 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-51ced849b5c6482a.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:10:13 INFO: Writing properties to tmp file: corenlp_server-0514dbdc965f4609.props\n",
            "2022-11-11 03:10:13 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-0514dbdc965f4609.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:10:44 INFO: Writing properties to tmp file: corenlp_server-f364dcf089f4416c.props\n",
            "2022-11-11 03:10:44 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-f364dcf089f4416c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:11:16 INFO: Writing properties to tmp file: corenlp_server-13e59898b9c645ed.props\n",
            "2022-11-11 03:11:16 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-13e59898b9c645ed.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:11:46 INFO: Writing properties to tmp file: corenlp_server-ca53a050eeeb46d9.props\n",
            "2022-11-11 03:11:46 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ca53a050eeeb46d9.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:12:13 INFO: Writing properties to tmp file: corenlp_server-b0d84a2421cd46b2.props\n",
            "2022-11-11 03:12:13 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b0d84a2421cd46b2.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:12:48 INFO: Writing properties to tmp file: corenlp_server-b3c25a94c3d3425b.props\n",
            "2022-11-11 03:12:48 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b3c25a94c3d3425b.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:13:24 INFO: Writing properties to tmp file: corenlp_server-c21132759a954769.props\n",
            "2022-11-11 03:13:24 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-c21132759a954769.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:14:01 INFO: Writing properties to tmp file: corenlp_server-b854e99e14844523.props\n",
            "2022-11-11 03:14:01 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b854e99e14844523.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:14:40 INFO: Writing properties to tmp file: corenlp_server-9d03dae6557d4923.props\n",
            "2022-11-11 03:14:40 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-9d03dae6557d4923.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:15:19 INFO: Writing properties to tmp file: corenlp_server-2977e8f0e42e4cf4.props\n",
            "2022-11-11 03:15:19 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2977e8f0e42e4cf4.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:15:56 INFO: Writing properties to tmp file: corenlp_server-ac36d4a4d427468a.props\n",
            "2022-11-11 03:15:56 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ac36d4a4d427468a.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:16:23 INFO: Writing properties to tmp file: corenlp_server-cd7b9c25f1c3484a.props\n",
            "2022-11-11 03:16:23 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-cd7b9c25f1c3484a.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:16:58 INFO: Writing properties to tmp file: corenlp_server-ddc62f7ce3e44902.props\n",
            "2022-11-11 03:16:58 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ddc62f7ce3e44902.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:17:52 INFO: Writing properties to tmp file: corenlp_server-0cd4d383a77e4ccb.props\n",
            "2022-11-11 03:17:52 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-0cd4d383a77e4ccb.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:18:24 INFO: Writing properties to tmp file: corenlp_server-cc7900a2c8bf4624.props\n",
            "2022-11-11 03:18:24 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-cc7900a2c8bf4624.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:18:55 INFO: Writing properties to tmp file: corenlp_server-9c9020b6156145a7.props\n",
            "2022-11-11 03:18:55 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-9c9020b6156145a7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:19:28 INFO: Writing properties to tmp file: corenlp_server-97e202ee4ad94b3e.props\n",
            "2022-11-11 03:19:28 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-97e202ee4ad94b3e.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:20:11 INFO: Writing properties to tmp file: corenlp_server-6cfa3cf9eb304af8.props\n",
            "2022-11-11 03:20:11 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-6cfa3cf9eb304af8.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:21:01 INFO: Writing properties to tmp file: corenlp_server-4b675577d0c54d19.props\n",
            "2022-11-11 03:21:01 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-4b675577d0c54d19.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:21:48 INFO: Writing properties to tmp file: corenlp_server-ce757dbb1c384b25.props\n",
            "2022-11-11 03:21:48 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ce757dbb1c384b25.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:22:24 INFO: Writing properties to tmp file: corenlp_server-5fbd54e354e94eba.props\n",
            "2022-11-11 03:22:24 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-5fbd54e354e94eba.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:23:00 INFO: Writing properties to tmp file: corenlp_server-107deb29b54c4030.props\n",
            "2022-11-11 03:23:00 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-107deb29b54c4030.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:23:35 INFO: Writing properties to tmp file: corenlp_server-bcfcfa1b4e1f450a.props\n",
            "2022-11-11 03:23:35 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-bcfcfa1b4e1f450a.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:24:12 INFO: Writing properties to tmp file: corenlp_server-45c2dd2fc2464c9c.props\n",
            "2022-11-11 03:24:12 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-45c2dd2fc2464c9c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:24:44 INFO: Writing properties to tmp file: corenlp_server-aa89eac297fb4e48.props\n",
            "2022-11-11 03:24:44 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-aa89eac297fb4e48.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:25:18 INFO: Writing properties to tmp file: corenlp_server-30acbba08a974c1c.props\n",
            "2022-11-11 03:25:18 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-30acbba08a974c1c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:25:52 INFO: Writing properties to tmp file: corenlp_server-a8c80ba315054559.props\n",
            "2022-11-11 03:25:52 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a8c80ba315054559.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:26:33 INFO: Writing properties to tmp file: corenlp_server-d7efc9b5c78440cc.props\n",
            "2022-11-11 03:26:33 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-d7efc9b5c78440cc.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:27:09 INFO: Writing properties to tmp file: corenlp_server-819d683bc97f422c.props\n",
            "2022-11-11 03:27:09 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-819d683bc97f422c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:27:45 INFO: Writing properties to tmp file: corenlp_server-7f4a7c0c17084323.props\n",
            "2022-11-11 03:27:45 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-7f4a7c0c17084323.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:28:15 INFO: Writing properties to tmp file: corenlp_server-d0a4332ac67844f0.props\n",
            "2022-11-11 03:28:15 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-d0a4332ac67844f0.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:28:51 INFO: Writing properties to tmp file: corenlp_server-4e607aae702d404a.props\n",
            "2022-11-11 03:28:51 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-4e607aae702d404a.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:29:29 INFO: Writing properties to tmp file: corenlp_server-5f326ddf470a437f.props\n",
            "2022-11-11 03:29:29 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-5f326ddf470a437f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:29:57 INFO: Writing properties to tmp file: corenlp_server-3cdcd7fa3f2b45a1.props\n",
            "2022-11-11 03:29:57 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-3cdcd7fa3f2b45a1.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:30:26 INFO: Writing properties to tmp file: corenlp_server-7a45750249fe4964.props\n",
            "2022-11-11 03:30:26 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-7a45750249fe4964.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:31:10 INFO: Writing properties to tmp file: corenlp_server-81b6766ea4dd4cda.props\n",
            "2022-11-11 03:31:10 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-81b6766ea4dd4cda.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:32:00 INFO: Writing properties to tmp file: corenlp_server-41d42d09e36c4ca7.props\n",
            "2022-11-11 03:32:00 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-41d42d09e36c4ca7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:32:27 INFO: Writing properties to tmp file: corenlp_server-79f82f10ba1148bb.props\n",
            "2022-11-11 03:32:27 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-79f82f10ba1148bb.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:33:02 INFO: Writing properties to tmp file: corenlp_server-8c71c180f4374c11.props\n",
            "2022-11-11 03:33:02 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-8c71c180f4374c11.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:33:46 INFO: Writing properties to tmp file: corenlp_server-25ddd41391e64b6f.props\n",
            "2022-11-11 03:33:46 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-25ddd41391e64b6f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:34:23 INFO: Writing properties to tmp file: corenlp_server-202ee29ab625412e.props\n",
            "2022-11-11 03:34:23 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-202ee29ab625412e.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:34:51 INFO: Writing properties to tmp file: corenlp_server-0aa0c4c04cd14cbf.props\n",
            "2022-11-11 03:34:51 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-0aa0c4c04cd14cbf.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:35:20 INFO: Writing properties to tmp file: corenlp_server-4893a69e857a472f.props\n",
            "2022-11-11 03:35:20 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-4893a69e857a472f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:35:52 INFO: Writing properties to tmp file: corenlp_server-0f91146a0e4d45e2.props\n",
            "2022-11-11 03:35:52 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-0f91146a0e4d45e2.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:36:30 INFO: Writing properties to tmp file: corenlp_server-99ddadccb07c4312.props\n",
            "2022-11-11 03:36:30 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-99ddadccb07c4312.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:37:13 INFO: Writing properties to tmp file: corenlp_server-d07533289f0340d5.props\n",
            "2022-11-11 03:37:13 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-d07533289f0340d5.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:37:45 INFO: Writing properties to tmp file: corenlp_server-305455d927964ceb.props\n",
            "2022-11-11 03:37:45 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-305455d927964ceb.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:38:19 INFO: Writing properties to tmp file: corenlp_server-893a8564799d4ad5.props\n",
            "2022-11-11 03:38:19 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-893a8564799d4ad5.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:38:56 INFO: Writing properties to tmp file: corenlp_server-bb32153aaf784c39.props\n",
            "2022-11-11 03:38:56 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-bb32153aaf784c39.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:39:27 INFO: Writing properties to tmp file: corenlp_server-002027e2246e4cb0.props\n",
            "2022-11-11 03:39:27 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-002027e2246e4cb0.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:40:08 INFO: Writing properties to tmp file: corenlp_server-793532339d1747a8.props\n",
            "2022-11-11 03:40:08 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-793532339d1747a8.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:40:59 INFO: Writing properties to tmp file: corenlp_server-5a5aaf8ee5aa49a0.props\n",
            "2022-11-11 03:40:59 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-5a5aaf8ee5aa49a0.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:41:41 INFO: Writing properties to tmp file: corenlp_server-8dc572dfdc4f4c52.props\n",
            "2022-11-11 03:41:41 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-8dc572dfdc4f4c52.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:42:15 INFO: Writing properties to tmp file: corenlp_server-8b5d5be051a5427d.props\n",
            "2022-11-11 03:42:15 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-8b5d5be051a5427d.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:42:42 INFO: Writing properties to tmp file: corenlp_server-16ba713b73da4073.props\n",
            "2022-11-11 03:42:42 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-16ba713b73da4073.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:43:14 INFO: Writing properties to tmp file: corenlp_server-ea13df827a3a4ee3.props\n",
            "2022-11-11 03:43:14 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ea13df827a3a4ee3.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:43:51 INFO: Writing properties to tmp file: corenlp_server-617f7f9d69b748d5.props\n",
            "2022-11-11 03:43:51 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-617f7f9d69b748d5.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:44:22 INFO: Writing properties to tmp file: corenlp_server-44a105be32d240dd.props\n",
            "2022-11-11 03:44:22 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-44a105be32d240dd.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:44:47 INFO: Writing properties to tmp file: corenlp_server-799ae8d5fe6243e7.props\n",
            "2022-11-11 03:44:47 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-799ae8d5fe6243e7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:45:17 INFO: Writing properties to tmp file: corenlp_server-2edba72ba0e84646.props\n",
            "2022-11-11 03:45:17 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2edba72ba0e84646.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:45:48 INFO: Writing properties to tmp file: corenlp_server-64238bd54d674b00.props\n",
            "2022-11-11 03:45:48 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-64238bd54d674b00.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:46:16 INFO: Writing properties to tmp file: corenlp_server-b36e5163409845e5.props\n",
            "2022-11-11 03:46:16 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b36e5163409845e5.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:46:44 INFO: Writing properties to tmp file: corenlp_server-ee50a33ab54a4185.props\n",
            "2022-11-11 03:46:44 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ee50a33ab54a4185.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:47:22 INFO: Writing properties to tmp file: corenlp_server-6ae0142f8ece453e.props\n",
            "2022-11-11 03:47:22 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-6ae0142f8ece453e.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:48:17 INFO: Writing properties to tmp file: corenlp_server-4d17190b964a4512.props\n",
            "2022-11-11 03:48:17 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-4d17190b964a4512.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:48:48 INFO: Writing properties to tmp file: corenlp_server-b3b4419b3d7d4694.props\n",
            "2022-11-11 03:48:48 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b3b4419b3d7d4694.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:49:27 INFO: Writing properties to tmp file: corenlp_server-e908f843bfc14e0c.props\n",
            "2022-11-11 03:49:27 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-e908f843bfc14e0c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:50:09 INFO: Writing properties to tmp file: corenlp_server-5c1f2c77a43e4a70.props\n",
            "2022-11-11 03:50:09 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-5c1f2c77a43e4a70.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:50:44 INFO: Writing properties to tmp file: corenlp_server-f701ab6d3d394c75.props\n",
            "2022-11-11 03:50:44 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-f701ab6d3d394c75.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:51:19 INFO: Writing properties to tmp file: corenlp_server-bf36ce19022b42ef.props\n",
            "2022-11-11 03:51:19 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-bf36ce19022b42ef.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:51:59 INFO: Writing properties to tmp file: corenlp_server-e3ff82abd8454119.props\n",
            "2022-11-11 03:51:59 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-e3ff82abd8454119.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:52:35 INFO: Writing properties to tmp file: corenlp_server-0ef477313ec24a6a.props\n",
            "2022-11-11 03:52:35 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-0ef477313ec24a6a.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:53:16 INFO: Writing properties to tmp file: corenlp_server-6e2d161eb2ef4748.props\n",
            "2022-11-11 03:53:16 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-6e2d161eb2ef4748.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:53:53 INFO: Writing properties to tmp file: corenlp_server-a2d286ee057b411f.props\n",
            "2022-11-11 03:53:53 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a2d286ee057b411f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:54:26 INFO: Writing properties to tmp file: corenlp_server-20f90be41d13411f.props\n",
            "2022-11-11 03:54:26 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-20f90be41d13411f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:54:59 INFO: Writing properties to tmp file: corenlp_server-df3733ea10b54f71.props\n",
            "2022-11-11 03:54:59 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-df3733ea10b54f71.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:55:33 INFO: Writing properties to tmp file: corenlp_server-081c0de40e0c42e2.props\n",
            "2022-11-11 03:55:33 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-081c0de40e0c42e2.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:56:01 INFO: Writing properties to tmp file: corenlp_server-fc54e85d24634960.props\n",
            "2022-11-11 03:56:01 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-fc54e85d24634960.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:56:36 INFO: Writing properties to tmp file: corenlp_server-4feb6a577ed444b1.props\n",
            "2022-11-11 03:56:36 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-4feb6a577ed444b1.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:57:19 INFO: Writing properties to tmp file: corenlp_server-ee044ca316804a50.props\n",
            "2022-11-11 03:57:19 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ee044ca316804a50.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:58:00 INFO: Writing properties to tmp file: corenlp_server-1309db2a8d484378.props\n",
            "2022-11-11 03:58:00 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-1309db2a8d484378.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:58:35 INFO: Writing properties to tmp file: corenlp_server-1d6937fa51994225.props\n",
            "2022-11-11 03:58:35 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-1d6937fa51994225.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 03:59:24 INFO: Writing properties to tmp file: corenlp_server-d507e63434d544cc.props\n",
            "2022-11-11 03:59:24 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-d507e63434d544cc.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:00:25 INFO: Writing properties to tmp file: corenlp_server-5762f51e1d1b483f.props\n",
            "2022-11-11 04:00:25 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-5762f51e1d1b483f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:01:03 INFO: Writing properties to tmp file: corenlp_server-c0be2dab23d2490d.props\n",
            "2022-11-11 04:01:03 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-c0be2dab23d2490d.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:01:37 INFO: Writing properties to tmp file: corenlp_server-6f7a87a88aa34efb.props\n",
            "2022-11-11 04:01:37 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-6f7a87a88aa34efb.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:02:17 INFO: Writing properties to tmp file: corenlp_server-b3bd986febc049a1.props\n",
            "2022-11-11 04:02:17 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b3bd986febc049a1.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:03:07 INFO: Writing properties to tmp file: corenlp_server-e1fdb37b496a4641.props\n",
            "2022-11-11 04:03:07 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-e1fdb37b496a4641.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:03:46 INFO: Writing properties to tmp file: corenlp_server-19e40b6fc8244324.props\n",
            "2022-11-11 04:03:46 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-19e40b6fc8244324.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:04:27 INFO: Writing properties to tmp file: corenlp_server-d583fffaee8e450b.props\n",
            "2022-11-11 04:04:27 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-d583fffaee8e450b.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:05:08 INFO: Writing properties to tmp file: corenlp_server-8bf9229fc5b3419c.props\n",
            "2022-11-11 04:05:08 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-8bf9229fc5b3419c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:05:40 INFO: Writing properties to tmp file: corenlp_server-604091cd5ee84235.props\n",
            "2022-11-11 04:05:40 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-604091cd5ee84235.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:06:08 INFO: Writing properties to tmp file: corenlp_server-7ae1133136f3422f.props\n",
            "2022-11-11 04:06:08 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-7ae1133136f3422f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:06:37 INFO: Writing properties to tmp file: corenlp_server-e9a6365fb113460e.props\n",
            "2022-11-11 04:06:37 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-e9a6365fb113460e.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:07:13 INFO: Writing properties to tmp file: corenlp_server-4a54d6c0d8974988.props\n",
            "2022-11-11 04:07:13 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-4a54d6c0d8974988.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:07:48 INFO: Writing properties to tmp file: corenlp_server-7d45296c2581463f.props\n",
            "2022-11-11 04:07:48 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-7d45296c2581463f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:08:30 INFO: Writing properties to tmp file: corenlp_server-f778bb7ea75e4161.props\n",
            "2022-11-11 04:08:30 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-f778bb7ea75e4161.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:09:00 INFO: Writing properties to tmp file: corenlp_server-ea0b1dd7d28749bd.props\n",
            "2022-11-11 04:09:00 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ea0b1dd7d28749bd.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:09:27 INFO: Writing properties to tmp file: corenlp_server-73b4d573b35d473b.props\n",
            "2022-11-11 04:09:27 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-73b4d573b35d473b.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:09:54 INFO: Writing properties to tmp file: corenlp_server-28f39fd510684851.props\n",
            "2022-11-11 04:09:54 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-28f39fd510684851.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:10:44 INFO: Writing properties to tmp file: corenlp_server-795dbd4d5bea4bf0.props\n",
            "2022-11-11 04:10:44 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-795dbd4d5bea4bf0.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:11:40 INFO: Writing properties to tmp file: corenlp_server-b70a8a8a117845ae.props\n",
            "2022-11-11 04:11:40 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b70a8a8a117845ae.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:12:25 INFO: Writing properties to tmp file: corenlp_server-e1bac96fa28945a8.props\n",
            "2022-11-11 04:12:25 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-e1bac96fa28945a8.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:13:04 INFO: Writing properties to tmp file: corenlp_server-67c098dd9f3b4c93.props\n",
            "2022-11-11 04:13:04 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-67c098dd9f3b4c93.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:13:49 INFO: Writing properties to tmp file: corenlp_server-c78fb9eff0ee4552.props\n",
            "2022-11-11 04:13:49 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-c78fb9eff0ee4552.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:14:40 INFO: Writing properties to tmp file: corenlp_server-dfaebbea92994cc9.props\n",
            "2022-11-11 04:14:40 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-dfaebbea92994cc9.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:15:27 INFO: Writing properties to tmp file: corenlp_server-2bbf4bf41837434d.props\n",
            "2022-11-11 04:15:27 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2bbf4bf41837434d.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:16:10 INFO: Writing properties to tmp file: corenlp_server-29d22f3a929c483e.props\n",
            "2022-11-11 04:16:10 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-29d22f3a929c483e.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:16:42 INFO: Writing properties to tmp file: corenlp_server-6fcb8f1f028f4dfc.props\n",
            "2022-11-11 04:16:42 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-6fcb8f1f028f4dfc.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:17:21 INFO: Writing properties to tmp file: corenlp_server-06dafc9b3d4a4bb7.props\n",
            "2022-11-11 04:17:21 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-06dafc9b3d4a4bb7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:17:53 INFO: Writing properties to tmp file: corenlp_server-53ca4b61f8c442b4.props\n",
            "2022-11-11 04:17:53 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-53ca4b61f8c442b4.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:18:27 INFO: Writing properties to tmp file: corenlp_server-711b123ce4344e45.props\n",
            "2022-11-11 04:18:27 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-711b123ce4344e45.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:19:15 INFO: Writing properties to tmp file: corenlp_server-ceae1597e73c41a7.props\n",
            "2022-11-11 04:19:15 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ceae1597e73c41a7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:20:00 INFO: Writing properties to tmp file: corenlp_server-f2bb13167ec44885.props\n",
            "2022-11-11 04:20:00 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-f2bb13167ec44885.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:20:44 INFO: Writing properties to tmp file: corenlp_server-643664faae4b4647.props\n",
            "2022-11-11 04:20:44 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-643664faae4b4647.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:21:26 INFO: Writing properties to tmp file: corenlp_server-3f8900b7437746f5.props\n",
            "2022-11-11 04:21:26 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-3f8900b7437746f5.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:21:59 INFO: Writing properties to tmp file: corenlp_server-212f638797ac4429.props\n",
            "2022-11-11 04:21:59 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-212f638797ac4429.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:22:33 INFO: Writing properties to tmp file: corenlp_server-c65d0c48ce9544de.props\n",
            "2022-11-11 04:22:33 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-c65d0c48ce9544de.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:22:58 INFO: Writing properties to tmp file: corenlp_server-62faea816f6f45c7.props\n",
            "2022-11-11 04:22:58 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-62faea816f6f45c7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:23:36 INFO: Writing properties to tmp file: corenlp_server-7a839468a68b4fb8.props\n",
            "2022-11-11 04:23:36 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-7a839468a68b4fb8.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:24:42 INFO: Writing properties to tmp file: corenlp_server-a4c9065ddad440cc.props\n",
            "2022-11-11 04:24:42 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a4c9065ddad440cc.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:25:28 INFO: Writing properties to tmp file: corenlp_server-b7335b5624c245b7.props\n",
            "2022-11-11 04:25:28 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b7335b5624c245b7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:26:05 INFO: Writing properties to tmp file: corenlp_server-22fe12d669cc419e.props\n",
            "2022-11-11 04:26:05 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-22fe12d669cc419e.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:26:42 INFO: Writing properties to tmp file: corenlp_server-d1ffb4f4cef940c8.props\n",
            "2022-11-11 04:26:42 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-d1ffb4f4cef940c8.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:27:14 INFO: Writing properties to tmp file: corenlp_server-1c1d141ddce0485b.props\n",
            "2022-11-11 04:27:14 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-1c1d141ddce0485b.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:27:50 INFO: Writing properties to tmp file: corenlp_server-474550edd6244e84.props\n",
            "2022-11-11 04:27:50 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-474550edd6244e84.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:28:26 INFO: Writing properties to tmp file: corenlp_server-6c29fb9b6a6b4c6c.props\n",
            "2022-11-11 04:28:26 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-6c29fb9b6a6b4c6c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:28:50 INFO: Writing properties to tmp file: corenlp_server-140334f6d0464fc7.props\n",
            "2022-11-11 04:28:50 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-140334f6d0464fc7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:29:21 INFO: Writing properties to tmp file: corenlp_server-2da6e10455a94229.props\n",
            "2022-11-11 04:29:21 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2da6e10455a94229.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:30:07 INFO: Writing properties to tmp file: corenlp_server-a5492870b2124671.props\n",
            "2022-11-11 04:30:07 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a5492870b2124671.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:30:43 INFO: Writing properties to tmp file: corenlp_server-fa4f3e3043214665.props\n",
            "2022-11-11 04:30:43 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-fa4f3e3043214665.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:31:25 INFO: Writing properties to tmp file: corenlp_server-29aa404dbce644cb.props\n",
            "2022-11-11 04:31:25 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-29aa404dbce644cb.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:32:25 INFO: Writing properties to tmp file: corenlp_server-c1902677b21a4c3b.props\n",
            "2022-11-11 04:32:25 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-c1902677b21a4c3b.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:33:20 INFO: Writing properties to tmp file: corenlp_server-f2b7ff4538284f94.props\n",
            "2022-11-11 04:33:20 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-f2b7ff4538284f94.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:34:16 INFO: Writing properties to tmp file: corenlp_server-a9219e9ac54745f1.props\n",
            "2022-11-11 04:34:16 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a9219e9ac54745f1.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:34:59 INFO: Writing properties to tmp file: corenlp_server-ac010a22b3184457.props\n",
            "2022-11-11 04:34:59 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ac010a22b3184457.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:35:56 INFO: Writing properties to tmp file: corenlp_server-8b5076886e32401e.props\n",
            "2022-11-11 04:35:56 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-8b5076886e32401e.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:36:59 INFO: Writing properties to tmp file: corenlp_server-702db5b1dfb740cd.props\n",
            "2022-11-11 04:36:59 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-702db5b1dfb740cd.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:37:34 INFO: Writing properties to tmp file: corenlp_server-b289afff02dd4d24.props\n",
            "2022-11-11 04:37:34 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-b289afff02dd4d24.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:38:20 INFO: Writing properties to tmp file: corenlp_server-80dbaf9e9dc240d6.props\n",
            "2022-11-11 04:38:20 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-80dbaf9e9dc240d6.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:39:02 INFO: Writing properties to tmp file: corenlp_server-31a58b8e90844e77.props\n",
            "2022-11-11 04:39:02 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-31a58b8e90844e77.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:39:43 INFO: Writing properties to tmp file: corenlp_server-1ef8a2526cb84f6c.props\n",
            "2022-11-11 04:39:43 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-1ef8a2526cb84f6c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:40:34 INFO: Writing properties to tmp file: corenlp_server-a49a0a1e40ed456c.props\n",
            "2022-11-11 04:40:34 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a49a0a1e40ed456c.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:41:32 INFO: Writing properties to tmp file: corenlp_server-74e3cac704d14e4a.props\n",
            "2022-11-11 04:41:32 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-74e3cac704d14e4a.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:42:12 INFO: Writing properties to tmp file: corenlp_server-c059a667bd084482.props\n",
            "2022-11-11 04:42:12 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-c059a667bd084482.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:42:52 INFO: Writing properties to tmp file: corenlp_server-bf1c3cdaab494a1f.props\n",
            "2022-11-11 04:42:52 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-bf1c3cdaab494a1f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:44:00 INFO: Writing properties to tmp file: corenlp_server-8231a795ed7b4990.props\n",
            "2022-11-11 04:44:00 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-8231a795ed7b4990.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:45:06 INFO: Writing properties to tmp file: corenlp_server-7707fc044f44414e.props\n",
            "2022-11-11 04:45:06 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-7707fc044f44414e.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:45:53 INFO: Writing properties to tmp file: corenlp_server-df6df458050a4aae.props\n",
            "2022-11-11 04:45:53 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-df6df458050a4aae.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:46:43 INFO: Writing properties to tmp file: corenlp_server-a953f70426ff4736.props\n",
            "2022-11-11 04:46:43 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a953f70426ff4736.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:47:19 INFO: Writing properties to tmp file: corenlp_server-1f84e683ba174f5b.props\n",
            "2022-11-11 04:47:19 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-1f84e683ba174f5b.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:47:59 INFO: Writing properties to tmp file: corenlp_server-ebd2be83e784439d.props\n",
            "2022-11-11 04:47:59 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-ebd2be83e784439d.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:48:41 INFO: Writing properties to tmp file: corenlp_server-2ac8012ce1ea430b.props\n",
            "2022-11-11 04:48:41 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2ac8012ce1ea430b.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:49:13 INFO: Writing properties to tmp file: corenlp_server-2aa02730eb5f4a44.props\n",
            "2022-11-11 04:49:13 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2aa02730eb5f4a44.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:49:47 INFO: Writing properties to tmp file: corenlp_server-aee2780c63ea44eb.props\n",
            "2022-11-11 04:49:47 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-aee2780c63ea44eb.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:50:34 INFO: Writing properties to tmp file: corenlp_server-1eebe910cbba4cf7.props\n",
            "2022-11-11 04:50:34 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-1eebe910cbba4cf7.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:51:29 INFO: Writing properties to tmp file: corenlp_server-da5ec85fdb214233.props\n",
            "2022-11-11 04:51:29 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-da5ec85fdb214233.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:52:23 INFO: Writing properties to tmp file: corenlp_server-e38681bd73364cfe.props\n",
            "2022-11-11 04:52:23 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-e38681bd73364cfe.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:52:51 INFO: Writing properties to tmp file: corenlp_server-0bf9681ace904b95.props\n",
            "2022-11-11 04:52:51 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-0bf9681ace904b95.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:53:23 INFO: Writing properties to tmp file: corenlp_server-4fe5919e54e54393.props\n",
            "2022-11-11 04:53:23 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-4fe5919e54e54393.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:54:01 INFO: Writing properties to tmp file: corenlp_server-48c32dac4ec04918.props\n",
            "2022-11-11 04:54:01 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-48c32dac4ec04918.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:54:44 INFO: Writing properties to tmp file: corenlp_server-eba7f722b8dc4e75.props\n",
            "2022-11-11 04:54:44 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-eba7f722b8dc4e75.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:55:17 INFO: Writing properties to tmp file: corenlp_server-0233adbea5b946fc.props\n",
            "2022-11-11 04:55:17 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-0233adbea5b946fc.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:55:48 INFO: Writing properties to tmp file: corenlp_server-f52646717ed14afb.props\n",
            "2022-11-11 04:55:48 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-f52646717ed14afb.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:56:18 INFO: Writing properties to tmp file: corenlp_server-37626b3600874d1f.props\n",
            "2022-11-11 04:56:18 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-37626b3600874d1f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:56:50 INFO: Writing properties to tmp file: corenlp_server-d513d03aeda24346.props\n",
            "2022-11-11 04:56:50 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-d513d03aeda24346.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:57:22 INFO: Writing properties to tmp file: corenlp_server-1d39508a48104793.props\n",
            "2022-11-11 04:57:22 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-1d39508a48104793.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:57:55 INFO: Writing properties to tmp file: corenlp_server-29e538b512744c01.props\n",
            "2022-11-11 04:57:55 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-29e538b512744c01.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:58:29 INFO: Writing properties to tmp file: corenlp_server-7b3451be2ad9477f.props\n",
            "2022-11-11 04:58:29 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-7b3451be2ad9477f.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:59:10 INFO: Writing properties to tmp file: corenlp_server-7ef8479a774d48b9.props\n",
            "2022-11-11 04:59:10 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-7ef8479a774d48b9.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 04:59:55 INFO: Writing properties to tmp file: corenlp_server-a388dec3b12c405d.props\n",
            "2022-11-11 04:59:55 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-a388dec3b12c405d.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:00:38 INFO: Writing properties to tmp file: corenlp_server-9d5e8984f53b4f73.props\n",
            "2022-11-11 05:00:38 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-9d5e8984f53b4f73.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:01:17 INFO: Writing properties to tmp file: corenlp_server-d012bf68768f4aea.props\n",
            "2022-11-11 05:01:17 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-d012bf68768f4aea.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:01:58 INFO: Writing properties to tmp file: corenlp_server-2e87f67b668a4040.props\n",
            "2022-11-11 05:01:58 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2e87f67b668a4040.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:02:30 INFO: Writing properties to tmp file: corenlp_server-48f40399f4cc4013.props\n",
            "2022-11-11 05:02:30 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-48f40399f4cc4013.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:03:08 INFO: Writing properties to tmp file: corenlp_server-37d1d2006a354e0a.props\n",
            "2022-11-11 05:03:08 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-37d1d2006a354e0a.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:03:48 INFO: Writing properties to tmp file: corenlp_server-77895b2dee5049f1.props\n",
            "2022-11-11 05:03:48 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-77895b2dee5049f1.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:04:34 INFO: Writing properties to tmp file: corenlp_server-48ea294fa85d4cd8.props\n",
            "2022-11-11 05:04:34 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-48ea294fa85d4cd8.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:05:28 INFO: Writing properties to tmp file: corenlp_server-2a41bec74aca4305.props\n",
            "2022-11-11 05:05:28 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-2a41bec74aca4305.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:06:10 INFO: Writing properties to tmp file: corenlp_server-3cc73509f6af4643.props\n",
            "2022-11-11 05:06:10 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-3cc73509f6af4643.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:06:42 INFO: Writing properties to tmp file: corenlp_server-00f062828de54a4b.props\n",
            "2022-11-11 05:06:42 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-00f062828de54a4b.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:07:18 INFO: Writing properties to tmp file: corenlp_server-6aa01231752648c2.props\n",
            "2022-11-11 05:07:18 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-6aa01231752648c2.props -annotators ner,openie -preload -outputFormat serialized\n",
            "2022-11-11 05:07:59 INFO: Writing properties to tmp file: corenlp_server-bff7bd34ad3e4286.props\n",
            "2022-11-11 05:07:59 INFO: Starting server with command: java -Xmx25G -cp /root/stanza_corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet False -serverProperties corenlp_server-bff7bd34ad3e4286.props -annotators ner,openie -preload -outputFormat serialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# allText = \"\"\"An interest rate is the rental price of money. The concepts of supply, demand and equilibrium apply in this market just as they do in other markets. This market is referred to as the market for loanable funds. In the market for loanable funds, the suppliers of funds are economic entities that currently have a surplus in their budget. In other words, they have more income than they currently want to spend; they would like to save some of their money and spend it in future time periods. Instead of just putting these savings in a box on a shelf for safekeeping until they want to spend it, they can let someone else borrow that money. In essence, they are renting that money to someone else, who pays a rental price called the interest rate.\"\"\"\n",
        "# allText = coref.coref_resolved(document=allText)\n",
        "# allTriples = []\n",
        "\n",
        "# with CoreNLPClient(timeout=150000000, be_quiet=False, annotators=['ner', 'openie'], memory='25G', endpoint='http://localhost:9001') as client:\n",
        "#   document = client.annotate(allText, output_format='json', properties={\"openie.triple.all_nominals\": True})\n",
        "#   allTriples.extend(addTriple(document, 0.5))\n"
      ],
      "metadata": {
        "id": "IauKzo0M5LpU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dr = {\"results\" : allTriples}\n",
        "json_object = json.dumps(dr)\n",
        "with open(\"stanfordopenie.json\", \"w\") as f:\n",
        "  f.write(json_object)"
      ],
      "metadata": {
        "id": "dPF4uFQje_yO"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f673e06532ef4ea6a048d928130c2571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be06c3de2e9a400984291e42c7f3fa5e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_70f3eb7850b54ec895c4ef9127cea5b1",
              "IPY_MODEL_95150d9cbb464e84a79fe9ad49d3729a",
              "IPY_MODEL_4fb33aa5803c4068ac32534dc1735c80"
            ]
          }
        },
        "be06c3de2e9a400984291e42c7f3fa5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70f3eb7850b54ec895c4ef9127cea5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a52495fcff8145b199504e78e6e20a69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_630305e60aae4f919deeecbf6970f71a"
          }
        },
        "95150d9cbb464e84a79fe9ad49d3729a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56488c9aa9df43e095e49cbc22affc5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 505225173,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 505225173,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be46836dea894eefa5ce6b6557191642"
          }
        },
        "4fb33aa5803c4068ac32534dc1735c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a6abeea72104f15ab1dea5ec64f5cc3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 505M/505M [00:02&lt;00:00, 205MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ac0b9ab794a415a92a092083dec6700"
          }
        },
        "a52495fcff8145b199504e78e6e20a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "630305e60aae4f919deeecbf6970f71a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56488c9aa9df43e095e49cbc22affc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be46836dea894eefa5ce6b6557191642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a6abeea72104f15ab1dea5ec64f5cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ac0b9ab794a415a92a092083dec6700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bacf141c77924929bab65e7318721226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cfe1cd69e6934b2394e87c049bfeafa9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f34734035ff7474da955db56d62ec081",
              "IPY_MODEL_a3ce6a5651a149848207482404f4ada1",
              "IPY_MODEL_9665dcafe47a4ac0bd8799f1583c61e9"
            ]
          }
        },
        "cfe1cd69e6934b2394e87c049bfeafa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f34734035ff7474da955db56d62ec081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a21a48a3deb49a3beb144943cf048f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4cd8a7bcd4649729aa0df972c08ef28"
          }
        },
        "a3ce6a5651a149848207482404f4ada1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ffbb8914adf4bf3b3b96ae46a6b07f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 414,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 414,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3add14c6d81b456593e3dd62f2971819"
          }
        },
        "9665dcafe47a4ac0bd8799f1583c61e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9eb5ece87a7c4430bd6841f02bc2ff44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 414/414 [00:00&lt;00:00, 14.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2027c78052e748758b6aa242f257756e"
          }
        },
        "8a21a48a3deb49a3beb144943cf048f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4cd8a7bcd4649729aa0df972c08ef28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ffbb8914adf4bf3b3b96ae46a6b07f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3add14c6d81b456593e3dd62f2971819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9eb5ece87a7c4430bd6841f02bc2ff44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2027c78052e748758b6aa242f257756e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a4809dac6cc41a29926ef329a408acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a21f1a0bd93746d1a34cbca986f21013",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_879707ddb2e649f586a0fdb38a640a7d",
              "IPY_MODEL_c91a5bfd73584db192b5edf5e017dda0",
              "IPY_MODEL_974dc072b36945f29c51300c2da13f01"
            ]
          }
        },
        "a21f1a0bd93746d1a34cbca986f21013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "879707ddb2e649f586a0fdb38a640a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be752455baa2482d81b3fed0ac331bed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_190e6b0b97c6469eaf40b760223b491a"
          }
        },
        "c91a5bfd73584db192b5edf5e017dda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5671cdc8ecc40d78d7d6a154f1357a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d311bf22556c4f7d87d171f15fcb5458"
          }
        },
        "974dc072b36945f29c51300c2da13f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_491b4b8abc3b4d21bc3e0ffe8a127f34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 332kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d7b6d9187494bb3af42387cabac692b"
          }
        },
        "be752455baa2482d81b3fed0ac331bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "190e6b0b97c6469eaf40b760223b491a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5671cdc8ecc40d78d7d6a154f1357a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d311bf22556c4f7d87d171f15fcb5458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "491b4b8abc3b4d21bc3e0ffe8a127f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d7b6d9187494bb3af42387cabac692b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b11ccc534e3453f9630d3f57c820ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1340dc8433c041f8bbe5c8825828f1f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85199b1136574be884cb07b67a178813",
              "IPY_MODEL_0471ce884d784e208c9c213c80adf839",
              "IPY_MODEL_552c7e39b9fd4ca59ada72830b6e2253"
            ]
          }
        },
        "1340dc8433c041f8bbe5c8825828f1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85199b1136574be884cb07b67a178813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5b5232d7961342369376afed5f9e604e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a49dcdb9dfc142cc9f9ff60912b61b01"
          }
        },
        "0471ce884d784e208c9c213c80adf839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5f7c8ad196674d00ba7cc64bcd0b2ec2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665132540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665132540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df4d573758ad4d3e870210dcf4f33352"
          }
        },
        "552c7e39b9fd4ca59ada72830b6e2253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8799cb11300c4278b7a91ca68ed15326",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665M/665M [00:30&lt;00:00, 23.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a8b5a242486412da048c2414d102bc0"
          }
        },
        "5b5232d7961342369376afed5f9e604e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a49dcdb9dfc142cc9f9ff60912b61b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f7c8ad196674d00ba7cc64bcd0b2ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df4d573758ad4d3e870210dcf4f33352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8799cb11300c4278b7a91ca68ed15326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a8b5a242486412da048c2414d102bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}